id: 02_heroku_logs_to_bigquery
namespace: logfile_analysis_pipeline
description: |
  Process Heroku access logs by extracting them from a Github repo first and upload them to GCS and BigQuery.

inputs: []

variables:
  file: "{{trigger.date | date('yyyy-MM-dd')}}.csv"
  gcs_file: "gs://{{kv('GCP_BUCKET_NAME')}}/{{vars.file}}"
  table: "{{kv('GCP_DATASET')}}.{{trigger.date | date('yyyy_MM_dd')}}"
  data: "{{outputs.extract.outputFiles[(trigger.date | date('yyyy-MM-dd')) ~ '.csv']}}"

tasks:
  - id: set_label
    type: io.kestra.plugin.core.execution.Labels
    labels:
      file: "{{render(vars.file)}}"

  - id: extract
    type: io.kestra.plugin.scripts.shell.Commands
    outputFiles:
      - "{{render(vars.file)}}"
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - wget -q -O {{render(vars.file)}} https://github.com/kkumyk/heroku_log_files/releases/download/daily-upload/{{render(vars.file)}}

  - id: upload_to_gcs
    type: io.kestra.plugin.gcp.gcs.Upload
    from: "{{render(vars.data)}}"
    to: "{{render(vars.gcs_file)}}"

  - id: bq_main_logfiles_table
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      CREATE TABLE IF NOT EXISTS `{{kv('GCP_PROJECT_ID')}}.{{kv('GCP_DATASET')}}.daily_data`
      (
          unique_row_id BYTES OPTIONS (description = 'A unique identifier for each hit, generated by hashing key hit attributes.'),
          filename STRING OPTIONS (description = 'The source filename from which the hit data was loaded.'),
          ip_address STRING OPTIONS (description = 'Identifies the clients IP address.'),
          timestamp TIMESTAMP OPTIONS (description = 'Indicates the date and time of the request.'),
          http_method STRING OPTIONS (description = 'Specifies the type of request.'),
          requested_url STRING OPTIONS (description = 'The page being accessed.'),
          http_protocol STRING OPTIONS (description = 'The protocol version used for the request.'),
          response_code INT64 OPTIONS (description = 'HTTP response status code.'),
          bytes_transferred INT64 OPTIONS (description = 'The size of data sent in response.'),
          referrer STRING OPTIONS (description = 'The page the visitor came from.'),
          user_agent STRING OPTIONS (description = 'A header sent during the HTTP request that tells the server what kind of` application (agent) is connecting to it.')
      )
      PARTITION BY DATE(timestamp);

  - id: bq_daily_data_table_ext
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      CREATE OR REPLACE EXTERNAL TABLE `{{kv('GCP_PROJECT_ID')}}.{{render(vars.table)}}_ext`
      (
          ip_address STRING OPTIONS (description = 'Identifies the clients IP address.'),
          timestamp TIMESTAMP OPTIONS (description = 'Indicates the date and time of the request.'),
          http_method STRING OPTIONS (description = 'Specifies the type of request.'),
          requested_url STRING OPTIONS (description = 'The page being accessed.'),
          http_protocol STRING OPTIONS (description = 'The protocol version used for the request.'),
          response_code INT64 OPTIONS (description = 'HTTP response status code.'),
          bytes_transferred INT64 OPTIONS (description = 'The size of data sent in response.'),
          referrer STRING OPTIONS (description = 'The page the visitor came from.'),
          user_agent STRING OPTIONS (description = 'A header sent during the HTTP request that tells the server what kind of application (agent) is connecting to it.')
          )
          OPTIONS (
              format = 'CSV',
              uris = ['{{render(vars.gcs_file)}}'],
              skip_leading_rows = 1,
              ignore_unknown_values = TRUE
          );

  - id: bq_daily_data_table_tmp
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      CREATE OR REPLACE TABLE `{{kv('GCP_PROJECT_ID')}}.{{render(vars.table)}}`
      AS
      SELECT
        -- Generate a unique row identifier using the most relevant columns
        MD5(CONCAT(
          COALESCE(ip_address, ""),
          COALESCE(CAST(timestamp AS STRING), ""),
          COALESCE(http_method, ""),
          COALESCE(requested_url, ""),
          COALESCE(CAST(response_code AS STRING), "")
        )) AS unique_row_id,
        
        -- Include the source filename as a column for traceability
        "{{render(vars.file)}}" AS filename,
        
        -- Include all columns from the external table
        *
      FROM `{{kv('GCP_PROJECT_ID')}}.{{render(vars.table)}}_ext`;

  - id: bq_daily_merge
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      MERGE INTO `{{kv('GCP_PROJECT_ID')}}.{{kv('GCP_DATASET')}}.daily_data` T
      USING `{{kv('GCP_PROJECT_ID')}}.{{render(vars.table)}}` S
      ON T.unique_row_id = S.unique_row_id
      WHEN NOT MATCHED THEN
        INSERT (unique_row_id, filename, ip_address, timestamp, http_method, requested_url, http_protocol, response_code, bytes_transferred, referrer, user_agent)
        VALUES (S.unique_row_id, S.filename, S.ip_address, S.timestamp, S.http_method, S.requested_url, S.http_protocol, S.response_code, S.bytes_transferred, S.referrer, S.user_agent);

  - id: purge_files
    type: io.kestra.plugin.core.storage.PurgeCurrentExecutionFiles
    description: To avoid cluttering your storage, we will remove the downloaded files.
    disabled: false

  - id: delete_external_table
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      DROP EXTERNAL TABLE `{{kv('GCP_PROJECT_ID')}}.{{render(vars.table)}}_ext`;

  - id: delete_tmp_table
    type: io.kestra.plugin.gcp.bigquery.Query
    sql: |
      DROP TABLE `{{kv('GCP_PROJECT_ID')}}.{{render(vars.table)}}`;

  # - id: delete_gcs_file
  #   type: io.kestra.plugin.gcp.gcs.Delete
  #   uri: "{{render(vars.gcs_file)}}"

pluginDefaults:
  - type: io.kestra.plugin.gcp
    values:
      serviceAccount: "{{ kv('GCP_CREDS') }}"
      projectId: "{{ kv('GCP_PROJECT_ID') }}"
      location: "{{ kv('GCP_LOCATION') }}"
      bucket: "{{ kv('GCP_BUCKET_NAME') }}"

triggers:
  - id: daily_logs_schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: "12 19 * * *"